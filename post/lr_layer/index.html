<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Amartya Sanyal">

  
  
  
    
  
  <meta name="description" content="In this paper ( Full Paper here), we investigate the relation of the intrinsic dimension of the representation space of deep networks with its robustness. To do this, we introduce an easy-to-implement, end-to-end trainable, scalable regularizer that enforces low rank structure in the representation space of deep networks; we conduct a variety of experiments to show that the resultant network is largely robust to adversarial and random perturbations. In addition, the low intrinsic dimension also means that the representations (and the model) can be compressed significantly without significant loss in accuracy.">

  
  <link rel="alternate" hreflang="en-us" href="amartya18x.github.io/post/lr_layer/">

  


  
  
  
  <meta name="theme-color" content="#3f51b5">
  

  
  
  
  <script src="/amartya18x.github.io/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/amartya18x.github.io/css/academic.css">

  




  


  

  <link rel="manifest" href="/amartya18x.github.io/index.webmanifest">
  <link rel="icon" type="image/png" href="/amartya18x.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/amartya18x.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="amartya18x.github.io/post/lr_layer/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@AmartyaSanyal">
  <meta property="twitter:creator" content="@AmartyaSanyal">
  
  <meta property="og:site_name" content="Amartya Sanyal">
  <meta property="og:url" content="amartya18x.github.io/post/lr_layer/">
  <meta property="og:title" content="Robustness via Deep Low-Rank Representations | Amartya Sanyal">
  <meta property="og:description" content="In this paper ( Full Paper here), we investigate the relation of the intrinsic dimension of the representation space of deep networks with its robustness. To do this, we introduce an easy-to-implement, end-to-end trainable, scalable regularizer that enforces low rank structure in the representation space of deep networks; we conduct a variety of experiments to show that the resultant network is largely robust to adversarial and random perturbations. In addition, the low intrinsic dimension also means that the representations (and the model) can be compressed significantly without significant loss in accuracy."><meta property="og:image" content="/amartya18x.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="/amartya18x.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-01-23T12:40:23&#43;00:00">
    
    <meta property="article:modified_time" content="2020-02-17T19:49:08&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "amartya18x.github.io/post/lr_layer/"
  },
  "headline": "Robustness via Deep Low-Rank Representations",
  
  "datePublished": "2020-01-23T12:40:23Z",
  "dateModified": "2020-02-17T19:49:08Z",
  
  "author": {
    "@type": "Person",
    "name": "Amartya Sanyal"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Amartya Sanyal",
    "logo": {
      "@type": "ImageObject",
      "url": "/amartya18x.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "In this paper ( Full Paper here), we investigate the relation of the intrinsic dimension of the representation space of deep networks with its robustness. To do this, we introduce an easy-to-implement, end-to-end trainable, scalable regularizer that enforces low rank structure in the representation space of deep networks; we conduct a variety of experiments to show that the resultant network is largely robust to adversarial and random perturbations. In addition, the low intrinsic dimension also means that the representations (and the model) can be compressed significantly without significant loss in accuracy."
}
</script>

  

  


  


  





  <title>Robustness via Deep Low-Rank Representations | Amartya Sanyal</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/amartya18x.github.io/">Amartya Sanyal</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/amartya18x.github.io/">Amartya Sanyal</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/amartya18x.github.io/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/amartya18x.github.io/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/amartya18x.github.io/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/amartya18x.github.io/#featured"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/amartya18x.github.io/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Robustness via Deep Low-Rank Representations</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Feb 17, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    8 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="amartya18x.github.io/post/lr_layer/#disqus_thread"></a>
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>In this paper (
<a href="https://arxiv.org/abs/1804.07090" target="_blank" rel="noopener">Full Paper here</a>), we investigate the relation of the <em>intrinsic</em> dimension of the representation space of deep networks with its robustness. To do this, we introduce an easy-to-implement, end-to-end trainable, scalable  regularizer that enforces low rank structure in the representation space of deep networks; we conduct a variety of experiments to show that the resultant network is largely robust to adversarial and random perturbations. In addition, the low <em>intrinsic</em> dimension also means that the representations (and the model) can be compressed significantly without significant loss in accuracy.</p>
<h3 id="low-rank-representations">Low Rank Representations</h3>
<div class="alert alert-hint">
  <div>
    For most models trained in a supervised fashion, the vector of
activations in the penultimate layer~(or a layer close to the penultimate layer) is a <em>learned</em> representation of the raw input.
  </div>
</div>
<p>The remarkable success of DNNs is primarily attributed to the discriminative quality of this learned representation space. However, despite their impressive performance, DNNs are known to be brittle to input perturbations. This raises concerns regarding the robustness of the factors captured by the learned representation space of DNNs. But we know that the factors captured by dimensionality reduction techniques, while being discriminative, are robust to input perturbations. This motivates the thesis behind this work:</p>
<div class="alert alert-hint">
  <div>
    If we enforce DNNs to learn representations that lie in a low-dimensional subspace (for the entire dataset), we would obtain more robust classifiers while preserving their discriminative power.
  </div>
</div>
<p>Precisely, we propose a low-rank regularizor (LR) that</p>
<ol>
<li>does not put any restriction on the network architecture.</li>
<li>is end-to-end trainable</li>
<li>is efficient in that it allows mini-batch training</li>
</ol>
<p>and provides benefits;</p>
<ol>
<li>it increases the robustness against black box and white box version of various adversarial attacks.</li>
<li>the generated representations  are discriminative and can be compressed due to it having a low <em>intrinsic</em> dimension.</li>
</ol>
<h3 id="problem-formulation">Problem Formulation</h3>
<p>Let $X = \{x_i\}_{i=1}^n$ and $Y = \{y_i\}_{i=1}^n$ be the set of inputs and outputs
of a given training dataset. By slight abuse of notation, we
define $A_\ell = f^{-}_\ell(X; \phi) =[a_1,\cdots,a_n]^\top\in \mathbb{R}^{n
\times m}$ to be the activation matrix of the entire dataset, so
that $a_i$ is the activation vector of the $i$-th sample. Note
that for most practical purposes $n\gg m$. In this setting,
the problem of learning low-rank representations can be
formulated as a constrained optimization problem as follows:
\begin{align}
\label{eq:opt_prob}
\min_{\theta, \phi}\mathcal{L}(X, Y; \theta,
\phi),~\text{s.t.}~~\mathrm{rank}(A_\ell) = r,\end{align}
where $\mathcal{L}(.)$ is the loss function and $r &lt; m$ is the
desired rank of the representations at layer $\ell$. The rank $r$ is a
hyperparameter. However, there are a few problems with this formulation.</p>
<p>First, the rank constraint is on a matrix</p>
<ul>
<li>whose size scales with dataset size.</li>
<li>which is not a parameter;</li>
<li>and it is not immediately clear if a Tikhonov regularizor exists that can achieve this.</li>
</ul>
<p>Second, minimizing the restriction of $A_\ell$ on a minibatch can result in orthogonal low rank spaces for each minibatch thus having a high dimensional subspace when all the minibatches are combined.</p>
<p>To mitigate these issues, we augment the initial problem as follows:</p>
<h4 id="augemented-problem-our-low-rank-regularizer">Augemented problem (our low rank regularizer)</h4>
<p>$$
\min_{\theta, \phi, W, b} \mathcal{L}(X, Y; \theta, \phi) + \mathcal{L}_c(A_\ell; W,b) + \mathcal{L}_n(A_\ell)$$
$$\text{s.t.,} W\in \mathbb{R}^{m\times m}, \mathrm{rank}(W) = r,~ b\in \mathbb{R}^m,A=f^{-}_\ell(X; \phi)
$$
where,
$$
\underbrace{\mathcal{L}_c(A; W, b) = \frac{1}{n} \sum_{i=1}^{n} \Big\|W^\top(a_i+b) - (a_i+b)\Big\|_2^2}_{\Large\text{Projection Loss}}$$
$$ \text{and} \quad \underbrace{\mathcal{L}_n(A) = \frac{1}{n}\sum_{i=1}^n \Big|1 - \|a_i\| \Big|}_{\Large \text{Norm Loss}}$$</p>
<p><strong>Projetion Loss</strong>: Minimizing the projection loss $\mathcal{L}_c$
ensures that the affine low-rank mappings ($AW$) of the activations
are close to the original ones i.e. $AW \approx A$. As $W$ is
low-rank, recalling sub-multiplicity of rank - $\mathrm{rank}(AW)\le \mathrm{min}(\mathrm{rank}(A),\mathrm{rank}(W))$,  $AW$ is also low-rank; thus implicitly~(due to
$AW\approx A$) it forces the original activations $A$ to
be low-rank. The bias $b$ allows for the activations to be translated before
projection.</p>
<p><strong>Norm Loss</strong>: However note that setting $A$ and $b$ close to zero trivially minimizes $\mathcal{L}_c$, especially when the activation dimension is large. We observed this to happen in practice as it is easier for the network to learn $\phi$ such that the activations and the bias are very small in order to minimize $\mathcal{L}_c$. To prevent this, we use $\mathcal{L}_n$ that acts as a norm constraint on the activation vector to keep the activations sufficiently large.</p>
<p>Intuitively, we learn a <em>virtual layer i.e.</em>($W,b$) during training that does two things.</p>
<ol>
<li>
<p>Learns a <strong>very</strong> low dimensional subspace that captures a large fraction of the information present in the representations/activations of the network on the training data.</p>
</li>
<li>
<p>Learns to encourage the representations/activations to lie as much as possible entirely on this low dimensional subspace.</p>
</li>
</ol>
<h3 id="adversarial-robustness-of-our-method">Adversarial Robustness of our method</h3>
<p>We recall that adversarial perturbations are well crafted~(almost
imperceptible) input perturbations that, when added to a clean input, flips the prediction
of the model on the input to an incorrect
one.</p>















<figure>


  <a data-fancybox="" href="/lr_layer/adv_pig.png" data-caption="An example of an image of a pig that is initially correctly classified by a classifier. On adding a small impertible perturbation, the same classifier mis-classifies it as an airliner. [a]">


  <img src="/lr_layer/adv_pig.png" alt=""  >
</a>


  
  
  <figcaption>
    An example of an image of a pig that is initially correctly classified by a classifier. On adding a small impertible perturbation, the same classifier mis-classifies it as an airliner. <a href='#adv_ref'>[a]</a>
  </figcaption>


</figure>

<p>We look at the adversarial robustness of our model as compared to a vanilla model i.e. one without our regularizor; and also with some other methods that impose constraints on the parameter space. We test it against two main adversaries -</p>
<ol>
<li>one that is computationally constrained where we measure the success of the adversarial attack for different computational budgets,</li>
<li>computationally unconstrained where we measure the amount of perturbation necessary for $99%$ mis-classification.</li>
</ol>
<p><strong>Computationally Constrained Adversary</strong></p>
<p>In the table below, we measure the adversarial accuracy of a ResNet50 model trained on the CIFAR10 dataset against an untargeted $\ell_{\infty}$  PGD adversary with the computational constraints (i.e. attack budgets measured in terms of $\ell_\infty$ radius and att. steps. Higher these values, stronger is the adversary.) The table  shows that our Low Rank regularizer has a much higher test accuracy than any of the other methods used.</p>
<table  class="table"  fgcolor="white" >
<caption >ResNet50 trained on CIFAR10. Low Rank uses our regularizor; SNIP <a href="#section1">[1]</a> is a pruning technique to to  enforce sparsity in parameters and SRN<a href="#section2"> [2]</a> is a technique to introduce a soft low rank structure in the parameter space.</caption>
  <thead>
    <tr bgcolor="white">
      <th style="width:12.5%" scope="col">Algorithm</th>
      <th class="text-center" colspan=8 style="width:87.5%" scope="col">Adversarial Test Accuracy</th>
    </tr>
    <tr bgcolor="white">
      <th style="width:12.5%" scope="col">$\ell_\infty$ radius</th>
      <th class="text-center" colspan=2 style="width:21.875%" scope="col"><sup>8</sup>&frasl;<sub>255</sub></th>
      <th class="text-center" colspan=2 style="width:21.875%" scope="col"><sup>10</sup>&frasl;<sub>255</sub></th>
      <th class="text-center" colspan=2 style="width:21.875%" scope="col"><sup>16</sup>&frasl;<sub>255</sub></th>
      <th class="text-center" colspan=2 style="width:21.875%" scope="col"><sup>20</sup>&frasl;<sub>255</sub></th>
     </tr>
     <tr bgcolor="white">	
      <th style="width:12.5%" scope="col">Att. steps</th>
      <th class="text-center" style="width:10.9375%" scope="col">7</th>
      <th class="text-center" style="width:10.9375%" scope="col">20</th>
      <th class="text-center" style="width:10.9375%" scope="col">7</th>
      <th class="text-center" style="width:10.9375%" scope="col">20</th>
      <th class="text-center" style="width:10.9375%" scope="col">7</th>
      <th class="text-center" style="width:10.9375%" scope="col">20</th>
      <th class="text-center" style="width:10.9375%" scope="col">7</th>
      <th class="text-center" style="width:10.9375%" scope="col">20</th>
     </tr>
  </thead>
  <tbody>
    <tr bgcolor="white">
  <th  scope="row">Vanilla</th>
  <td> 43.1 </td>
  <td> 31.0  </td>
  <td> 38.5 </td>
  <td> 21.8 </td>
  <td> 31.2 </td>
  <td> 7.8   </td>
  <td> 28.9 </td>
  <td> 4.5 </td> 
    </tr>
    <tr  bgcolor="white">
      <th scope="row">SNIP <a href="#section1">[1]</a> </th>
     <td>   29.4 </td>
     <td> 14.5  </td>
     <td> 25.0 </td>
     <td> 8.0 </td>
     <td> 18.5 </td>
     <td> 1.3  </td>
     <td> 16.2 </td>
     <td> 0.4 </td>
    </tr>
     <tr  bgcolor="white">
      <th scope="row">SRN <a href="#section1">[2]</a> </th>
    <td> 47.8</td>
    <td> 37.6</td>
    <td> 44.4</td>
    <td> 31.4</td>
    <td> 39.8</td>
    <td>  21.3</td>
    <td> 37.5</td>
    <td> 18.4</td>
    </tr>
     <tr bgcolor="white"> 
      <th scope="row">Low Rank (Ours)</th>
    <td> $\mathbf{79.1}$ </td>
    <td> $\mathbf{78.5}$  </td>
    <td> $\mathbf{78.6}$ </td>
    <td> $\mathbf{78.1}$  </td>
    <td> $\mathbf{77.9}$ </td>
    <td> $\mathbf{77.0}$  </td>
    <td> $\mathbf{77.1}$ </td>
    <td> $\mathbf{76.6}$ </td>
    </tr>
  </tbody>
</table>
<p><strong>Computationally UnConstrained Adversary (Deepfool) <a href="#section3"> [3]</a></strong></p>
<p>We also look at the amount of adversarial perturbation that is necessary to fool our classifier as opposed to a vanilla model. Measured numerically, ours requires an order of magnitude more than normal models. Please refer to our paper for the exact values. If visualized, the images appear as below and the adversarial images for teh Low-Rank model (LR) are significantly more different from the original model than those for the vanilla model.</p>
<table>
<thead>
<tr>
<th align="center">Original Image</th>
<th align="center">Vanilla Model</th>
<th align="center">Low Rank Model</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/orig_1.png" >


  <img src="/lr_layer/orig_1.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/N-LR_1.png" >


  <img src="/lr_layer/N-LR_1.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/2-LR_1.png" >


  <img src="/lr_layer/2-LR_1.png" alt=""  >
</a>



</figure>
</td>
</tr>
<tr>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/orig_3.png" >


  <img src="/lr_layer/orig_3.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/N-LR_3.png" >


  <img src="/lr_layer/N-LR_3.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/2-LR_3.png" >


  <img src="/lr_layer/2-LR_3.png" alt=""  >
</a>



</figure>
</td>
</tr>
</tbody>
</table>
<h3 id="noise-stability">Noise Stability</h3>
<p>We explain this robustness by showing that the noise-stability of the low rank representations are much more than those of vanilla models. More specifically, we show two different experiments</p>
<ol>
<li><b> Random Pixel Perturbation: </b> When a random subset (each pixel is chosen iid with probability $p$)  of the pixels of a image are perturbed with a random multi-variate gaussian noise, the test accuracy of our low-rank models drops much slower than that of a vanilla model.</li>
</ol>
<table>
<thead>
<tr>
<th>Pert. Prob. $p$</th>
<th>$0.4$</th>
<th>$0.6$</th>
<th>$0.8$</th>
<th>$1.0$</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>$69.7$</td>
<td>$26.1$</td>
<td>$12.6$</td>
<td>$11.3$</td>
</tr>
<tr>
<td>Low-Rank (Ours)</td>
<td>$\mathbf{75.1}$</td>
<td>$\mathbf{34.2}$</td>
<td>$\mathbf{15.8}$</td>
<td>$\mathbf{13.0}$</td>
</tr>
</tbody>
</table>
<p>2.<b> Noise-Stability of Representations:</b> We measure the ratio of the norm of the perturbation induced in the representation space with to the norm of the perturbation in the input space for adversarial perturbations. In the following diagram, x-axis measures $$\text{x-axis}:\dfrac{\|\delta\|_2^2}{\|x\|_2^2}\quad \text{y-axis}:\dfrac{\|f_\ell^{-}(x+\delta) - f_\ell^{-}(x)\|_2^2}{\|f_\ell^{-}(x)\|_2^2}$$
White box attacks are attacks where the perturbation is constructed using the model to be attacked, black box models are attacks where the vanilla model is used to construct the attack.</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">White Box Attack</th>
<th align="center">Black Box Attack</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/pert_legend.png" >


  <img src="/lr_layer/pert_legend.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/pert_comp_fig.png" >


  <img src="/lr_layer/pert_comp_fig.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/bb_pert_comp_fig.png" >


  <img src="/lr_layer/bb_pert_comp_fig.png" alt=""  >
</a>



</figure>
</td>
</tr>
</tbody>
</table>
<h3 id="further-observations-in-the-paper">Further observations in the paper</h3>
<ol>
<li><strong>Layer Cusion</strong>: Arora et. al  <a href="#section4"> [4]</a> define a quantity called layer cushion, which is intuitively the reciprocal of noise-sensitivity to random gaussian noise measured on the real dataset. We measure this quantity for all our networks and show that this quantity is much higher for our networks.</li>
<li><strong>Compressing Representations</strong>: Due to the low <em>intrinsic dimension</em> of the low rank representations, even after aggressive compression ($400x$) outhe low rank model looses only $6\%$ in accuracy as opposed to the vanilla model which looses more than $27\%$.</li>
<li><strong>Compressing Models</strong>: We also throw away the latter parts of the model (after the low rank representation) and train a small linear model ($8M$ replaced with $160k$ parameters) yielding less than $1\%$ drop in accuracy.</li>
<li><strong>Discriminative Representations</strong>: When visualized with PCA (and colored according to classes), the low rank model yields representations that are more discriminative in nature in the sense that a low dimensional lienar classifier can classify it with a much larger margin than for vanilla models.</li>
</ol>
<table>
<thead>
<tr>
<th align="center">Vanilla Model</th>
<th align="center">Low Rank Model</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/coarse_label_PCA_NLR.png" >


  <img src="/lr_layer/coarse_label_PCA_NLR.png" alt=""  >
</a>



</figure>
</td>
<td align="center">














<figure>


  <a data-fancybox="" href="/lr_layer/coarse_label_PCA.png" >


  <img src="/lr_layer/coarse_label_PCA.png" alt=""  >
</a>



</figure>
</td>
</tr>
</tbody>
</table>
<p>For the full paper refer to <a href="https://arxiv.org/abs/1804.07090">https://arxiv.org/abs/1804.07090</a>.</p>
<p style="font-size:11px" id="adv_ref"> [a] Picture taken from https://medium.com/@smkirthishankar/the-unusual-effectiveness-of-adversarial-attacks-e1314d0fa4d3 </p>
<p style="font-size:11px"  id="section1">[1] Lee, Namhoon, Thalaiyasingam Ajanthan, and Philip HS Torr. "Snip: Single-shot network pruning based on connection sensitivity." International Conference on Learning Representations (2019). </p>
<p style="font-size:11px"  id="section1">[2] Sanyal, Amartya, Philip HS Torr, and Puneet K. Dokania. "Stable Rank Normalization for Improved Generalization in Neural Networks and GANs."  International Conference on Learning Representations (2020). </p>
<p style="font-size:11px"  id="section3">[3] Moosavi-Dezfooli, Seyed-Mohsen, Alhussein Fawzi, and Pascal Frossard. "Deepfool: a simple and accurate method to fool deep neural networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. </p>
<p style="font-size:11px"  id="section4">[4] Arora, Sanjeev, et al. "Stronger generalization bounds for deep nets via a compression approach." arXiv preprint arXiv:1802.05296 (2018). </p>
    </div>

    





<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=amartya18x.github.io/post/lr_layer/&amp;text=Robustness%20via%20Deep%20Low-Rank%20Representations" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=amartya18x.github.io/post/lr_layer/&amp;t=Robustness%20via%20Deep%20Low-Rank%20Representations" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Robustness%20via%20Deep%20Low-Rank%20Representations&amp;body=amartya18x.github.io/post/lr_layer/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=amartya18x.github.io/post/lr_layer/&amp;title=Robustness%20via%20Deep%20Low-Rank%20Representations" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Robustness%20via%20Deep%20Low-Rank%20Representations%20amartya18x.github.io/post/lr_layer/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=amartya18x.github.io/post/lr_layer/&amp;title=Robustness%20via%20Deep%20Low-Rank%20Representations" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  






  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/amartya18x.github.io/authors/admin/avatar_hue776a334b902d7828bf5c7a8aa11ccb3_924185_270x270_fill_q90_lanczos_center.jpg" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title"><a href="amartya18x.github.io">Amartya Sanyal</a></h5>
      <h6 class="card-subtitle">DPhil (PhD) Student in Computer Science</h6>
      <p class="card-text">I am interested in a theoretical understanding the behaviours of deep neural networks and designing practical algorithms to avoid some of its unwanted artifacts.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:amartya18x@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/AmartyaSanyal" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=cRLqsyYAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/amartya18x" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/amartya18x.github.io/files/cv.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>




<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "amartyasanyal" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>






  
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.4/mermaid.min.js" integrity="sha256-JEqEejGt4tR35L0a1zodzsV0/PJ6GIf7J4yDtywdrH8=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/amartya18x.github.io/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    <script id="dsq-count-scr" src="https://amartyasanyal.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/amartya18x.github.io/js/academic.min.a8d7005002cb4a052fd6d721e83df9ba.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
